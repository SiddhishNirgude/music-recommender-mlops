# ğŸµ Music Recommender MLOps Pipeline

[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-available-blue.svg)](https://www.docker.com/)
[![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-green.svg)](https://github.com/features/actions)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

End-to-end production-ready MLOps pipeline for music recommendations using Alternating Least Squares (ALS) collaborative filtering on the Last.fm-360K dataset. Demonstrates industry best practices including experiment tracking, automated testing, containerized deployment, and real-time monitoring.

![Master Architecture](diagrams/00_MASTER_DIAGRAM.png)

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [Dataset](#-dataset)
- [Model Performance](#-model-performance)
- [Technologies](#-technologies)
- [Project Structure](#-project-structure)
- [Development](#-development)
- [Monitoring](#-monitoring)
- [CI/CD Pipeline](#-cicd-pipeline)
- [Production Deployment](#-production-deployment)
- [Documentation](#-documentation)
- [Contributing](#-contributing)
- [Team](#-team)
- [License](#-license)

---

## âœ¨ Features

### **MLOps Infrastructure**
- ğŸ”„ **Data Version Control** - DVC with AWS S3 backend for reproducible data pipelines
- ğŸ“Š **Experiment Tracking** - MLflow tracking 7 hyperparameter configurations
- ğŸ§ª **Automated Testing** - 52 pytest tests (98% passing) with GitHub Actions CI/CD
- ğŸ³ **Containerization** - Docker Compose orchestrating 4 microservices
- ğŸ“ˆ **Real-time Monitoring** - Prometheus + Grafana with 6 dashboard panels
- ğŸš€ **Production Ready** - Health checks, auto-restart, graceful degradation

### **Machine Learning**
- **Algorithm**: Alternating Least Squares (ALS) collaborative filtering
- **Dataset**: Last.fm-360K (17.5M interactions, 358K users, 126K artists)
- **Performance**: 1.37% Precision@10, 0.88% MAP@10, 1.44% NDCG@10
- **Inference Speed**: 180ms average response time
- **Model Size**: 370 MB (150 latent factors)

### **User Interface**
- ğŸ¨ **Streamlit Web App** - Intuitive mood-based recommendations (12 moods)
- ğŸ”Œ **FastAPI Backend** - RESTful API with 6 endpoints
- ğŸ“Š **Interactive Docs** - Automatic Swagger UI documentation
- ğŸ¯ **Features**: Mood recommendations, artist similarity, top charts, random discovery

---

## ğŸ—ï¸ Architecture

### **System Components**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA LAYER                               â”‚
â”‚  Last.fm (17.5M) â†’ AWS S3 (1.64GB) â†’ DVC â†’ Preprocessing        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MODEL LAYER                               â”‚
â”‚  ALS Training (7 experiments) â†’ MLflow â†’ Model Registry          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DEPLOYMENT LAYER                            â”‚
â”‚  Docker: FastAPI (8000) + Streamlit (8501) + Prometheus (9090)  â”‚
â”‚          + Grafana (3000)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MONITORING LAYER                              â”‚
â”‚  Metrics: 30-50 req/min, 0.18s latency, 0% errors              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Flows:**
1. **Data Pipeline**: S3 â†’ DVC â†’ Preprocessing â†’ Train/Test Split (80/20)
2. **Model Training**: ALS (factors=150) â†’ Evaluation â†’ MLflow Registry
3. **Deployment**: Docker Compose â†’ 4 Services â†’ Health Checks
4. **Monitoring**: Prometheus Scrape (10s) â†’ Grafana Dashboards

---

## ğŸš€ Quick Start

### **Prerequisites**
- Docker Desktop 4.0+
- Python 3.12
- Git
- 8GB RAM recommended

### **1. Clone Repository**
```bash
git clone https://github.com/SiddhishNirgude/music-recommender-mlops.git
cd music-recommender-mlops
```

### **2. Configure AWS (for DVC data access)**
```bash
# Install AWS CLI
brew install awscli  # macOS
# OR: pip install awscli

# Configure credentials
aws configure
# AWS Access Key ID: [provided separately]
# AWS Secret Access Key: [provided separately]
# Default region: us-east-1
# Default output format: json
```

### **3. Install Dependencies**
```bash
pip install -r requirements.txt
```

### **4. Download Data**
```bash
# Pull dataset from S3 via DVC (~1.64 GB, takes 2-3 minutes)
dvc pull
```

### **5. Start All Services**
```bash
# Start Docker containers (API, UI, Prometheus, Grafana)
docker-compose up -d

# Wait for services to initialize (30 seconds)
sleep 30

# Verify all containers running
docker ps
```

### **6. Access Applications**

| Service | URL | Credentials | Purpose |
|---------|-----|-------------|---------|
| **Streamlit UI** | http://localhost:8501 | None | Main user interface |
| **FastAPI Docs** | http://localhost:8000/docs | None | API documentation & testing |
| **Grafana** | http://localhost:3000 | admin/admin | Monitoring dashboards |
| **Prometheus** | http://localhost:9090 | None | Metrics database |
| **MLflow** | http://localhost:5000 | None | Experiment tracking |

### **7. Test the System**
```bash
# Check API health
curl http://localhost:8000/health

# Expected: {"status":"healthy","model_loaded":true}

# Generate traffic for monitoring demo
python scripts/generate_traffic.py
# Press Ctrl+C to stop
```

### **8. Stop Services**
```bash
docker-compose down
```

**Total setup time: ~10 minutes** (excluding data download)

---

## ğŸ“Š Dataset

### **Last.fm-360K**
- **Source**: [Last.fm Dataset - 360K users](http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/lastfm-360K.html)
- **Size**: 1.64 GB (raw TSV)
- **Interactions**: 17,535,655 user-artist play counts
- **Users**: 358,622 unique users
- **Artists**: 126,442 unique artists
- **Sparsity**: 99.97% (extremely sparse)
- **Type**: Implicit feedback (play counts, not ratings)

### **Preprocessing**
```python
# Quality filters applied:
- Remove users with < 5 interactions (eliminate noise)
- Remove artists with < 3 listeners (focus on established content)
- Aggregate duplicate user-artist pairs
- Create 80/20 train-test split (temporal per user)
- Confidence weighting: confidence = 1 + 40 Ã— play_count
```

**Processed Data:**
- Training: 14,021,366 interactions (80%)
- Testing: 3,323,105 interactions (20%)
- Matrix: 358,622 Ã— 126,442 (sparse CSR format)

---

## ğŸ¯ Model Performance

### **Best Configuration**
```yaml
Model: Alternating Least Squares (ALS)
Factors: 150
Iterations: 25
Regularization: 0.01
Alpha: 40 (confidence weighting)
Training Time: 243 minutes
Model Size: 370 MB
```

### **Evaluation Metrics (Test Set)**

| Metric | Value | Interpretation |
|--------|-------|----------------|
| **Precision@10** | 1.37% | 1-2 relevant items per 10 recommendations |
| **MAP@10** | 0.88% | Ranking quality (rewards early relevant items) |
| **NDCG@10** | 1.44% | Position-weighted relevance |
| **Training Time** | 243 min | Full dataset, 150 factors |
| **Inference Time** | 0.18s | Average response time |

**Context:** These metrics are typical for implicit feedback systems with extreme sparsity (99.97%). Random guessing would achieve ~0.0008% precision (1,500Ã— worse). Our model matches academic benchmarks on Last.fm dataset.

### **Experiment Comparison**

| Factors | Iterations | Precision@10 | Training Time | Selected |
|---------|-----------|--------------|---------------|----------|
| 150 | 25 | 1.37% | 243 min | âŒ (too slow) |
| **125** | **25** | **1.20%** | **13 min** | âœ… **BEST** |
| 100 | 20 | 0.85% | 6 min | âŒ (lower accuracy) |
| 75 | 20 | 0.69% | 4 min | âŒ (lower accuracy) |
| 50 | 15 | 0.34% | 2 min | âŒ (too low accuracy) |

**Decision:** Factors=125 selected for production (40% better than baseline, 18Ã— faster than best model)

---

## ğŸ› ï¸ Technologies

### **Machine Learning & Data**
- **Python 3.12** - Core language
- **implicit 0.7.2** - ALS implementation
- **NumPy / SciPy** - Matrix operations
- **pandas** - Data preprocessing
- **scikit-learn** - Train-test split, metrics

### **MLOps Infrastructure**
- **DVC 3.x** - Data version control
- **AWS S3** - Remote data storage
- **MLflow 2.x** - Experiment tracking & model registry
- **Docker / Docker Compose** - Containerization

### **API & Frontend**
- **FastAPI 0.109** - REST API framework
- **Streamlit 1.31** - Web UI
- **Pydantic** - Data validation
- **Uvicorn** - ASGI server

### **Monitoring & Observability**
- **Prometheus 2.x** - Metrics collection
- **Grafana 10.x** - Visualization dashboards
- **prometheus-client** - Python instrumentation

### **CI/CD & Testing**
- **GitHub Actions** - Continuous integration
- **pytest 8.x** - Testing framework (52 tests)
- **flake8** - Code linting
- **black / isort** - Code formatting

---

## ğŸ“ Project Structure

```
music-recommender-mlops/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw Last.fm dataset (DVC tracked)
â”‚   â””â”€â”€ processed/              # Preprocessed train/test data
â”‚       â”œâ”€â”€ train_interactions.csv
â”‚       â”œâ”€â”€ test_interactions.csv
â”‚       â”œâ”€â”€ user_item_matrix.npz
â”‚       â”œâ”€â”€ user_mapping.json
â”‚       â””â”€â”€ artist_mapping.json
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ als_model.pkl          # Trained ALS model (370 MB)
â”‚   â”œâ”€â”€ user_factors.npy       # User embeddings (358K Ã— 150)
â”‚   â”œâ”€â”€ item_factors.npy       # Artist embeddings (126K Ã— 150)
â”‚   â””â”€â”€ model_metadata.json    # Model configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py           # FastAPI application
â”‚   â”‚   â””â”€â”€ models.py         # Pydantic schemas
â”‚   â”œâ”€â”€ streamlit_app.py      # Streamlit UI
â”‚   â””â”€â”€ preprocessing/
â”‚       â””â”€â”€ preprocess.py     # Data cleaning pipeline
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_preprocessing.py  # Execute preprocessing
â”‚   â”œâ”€â”€ train_model.py        # Train ALS model
â”‚   â”œâ”€â”€ run_experiments.py    # Hyperparameter tuning
â”‚   â”œâ”€â”€ analyze_experiments.py # Compare MLflow runs
â”‚   â””â”€â”€ generate_traffic.py   # Load testing
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py           # API endpoint tests
â”‚   â”œâ”€â”€ test_model.py         # Model functionality tests
â”‚   â””â”€â”€ test_preprocessing.py # Data pipeline tests
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml        # Prometheus config
â”‚   â””â”€â”€ grafana/
â”‚       â””â”€â”€ provisioning/     # Grafana datasources
â”œâ”€â”€ diagrams/                  # Architecture diagrams (7 PDFs)
â”‚   â”œâ”€â”€ 00_MASTER_DIAGRAM.pdf
â”‚   â”œâ”€â”€ 01_data_pipeline.pdf
â”‚   â”œâ”€â”€ 02_model_training.pdf
â”‚   â”œâ”€â”€ 03_deployment.pdf
â”‚   â”œâ”€â”€ 04_user_request.pdf
â”‚   â”œâ”€â”€ 05_cicd.pdf
â”‚   â””â”€â”€ 06_monitoring.pdf
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ PROJECT_START.md      # Startup guide
â”‚   â”œâ”€â”€ PROJECT_STOP.md       # Shutdown guide
â”‚   â”œâ”€â”€ PRODUCTION_RISKS.md   # Risk assessment (13 risks)
â”‚   â””â”€â”€ PROJECT_DOCUMENTATION.docx  # Complete project docs
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml            # GitHub Actions pipeline
â”œâ”€â”€ docker-compose.yml        # Service orchestration
â”œâ”€â”€ Dockerfile               # API container image
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .dvc/                    # DVC configuration
â”œâ”€â”€ data.dvc                 # DVC data tracker
â”œâ”€â”€ mlruns/                  # MLflow experiment data
â”œâ”€â”€ experiments_comparison.csv  # Model comparison results
â””â”€â”€ README.md               # This file
```

---

## ğŸ’» Development

### **Running Locally (Without Docker)**

**Start FastAPI:**
```bash
cd src/api
uvicorn main:app --reload --port 8000
# Access: http://localhost:8000/docs
```

**Start Streamlit:**
```bash
streamlit run src/streamlit_app.py
# Access: http://localhost:8501
```

**Start MLflow:**
```bash
mlflow ui
# Access: http://localhost:5000
```

### **Training New Model**

```bash
# Preprocess data (if not done)
python scripts/run_preprocessing.py

# Train with default config
python scripts/train_model.py

# Or run hyperparameter experiments
python scripts/run_experiments.py
```

### **Running Tests**

```bash
# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_api.py -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

### **Code Quality**

```bash
# Format code
black src/ tests/
isort src/ tests/

# Lint
flake8 src/ tests/ --max-line-length=100

# Type checking
mypy src/
```

---

## ğŸ“ˆ Monitoring

### **Grafana Dashboard Panels**

**Access:** http://localhost:3000 (admin/admin)

1. **Requests Per Minute**
   - Current: 30-50 req/min
   - PromQL: `rate(http_requests_total[1m]) * 60`

2. **Average Response Time**
   - Current: 0.18 seconds
   - Thresholds: Green <0.5s, Yellow <1s, Red >1s

3. **Error Rate**
   - Current: 0%
   - Alert threshold: >1% warning, >5% critical

4. **Total Recommendations**
   - Cumulative counter since startup

5. **Top 5 Moods**
   - Heartbreak: 38%
   - Party: 22%
   - Chill: 15%
   - Motivation: 12%
   - Focus: 8%

6. **Model Status**
   - Users: 358,622
   - Artists: 126,442
   - Factors: 150

### **Prometheus Metrics**

**Endpoint:** http://localhost:9090

**Available Metrics:**
- `http_requests_total` - Total API requests
- `http_request_duration_seconds` - Response time histogram
- `api_errors_total` - Error count
- `recommendations_total` - Recommendations served
- `mood_requests_total` - Requests per mood
- `model_loaded` - Model status (0/1)

### **Generating Test Traffic**

```bash
# Simulate 30 req/min for monitoring demo
python scripts/generate_traffic.py

# Let it run for 2-3 minutes to populate Grafana
# Press Ctrl+C to stop
```

---

## ğŸ”„ CI/CD Pipeline

### **GitHub Actions Workflow**

**Triggers:** Push to `main`, Pull Requests

**Pipeline Stages:**

1. **Code Quality** (~30s)
   - Black formatting check
   - isort import sorting
   - Flake8 linting (PEP 8)

2. **Testing** (~2 min)
   - 52 pytest tests
   - Coverage report
   - Integration tests

3. **Docker Build** (~1 min)
   - Build API image
   - Build Streamlit image
   - Tag with commit SHA

4. **Security Scan** (~30s)
   - Dependency vulnerability check
   - Container image scanning

**Total Duration:** 3-5 minutes

**Current Status:** âœ… 52/53 tests passing (98%)

**View Pipeline:** https://github.com/SiddhishNirgude/music-recommender-mlops/actions

---

## ğŸš€ Production Deployment

### **Current Status**
- âœ… Docker Compose (local/single-server deployment)
- âœ… Health checks & auto-restart
- âœ… Monitoring & alerting infrastructure
- âš ï¸ Kubernetes deployment (planned)

### **Docker Compose Deployment**

```bash
# Production startup
docker-compose up -d

# Check service health
docker-compose ps

# View logs
docker-compose logs -f api

# Scale API replicas (manual)
docker-compose up -d --scale api=3
```

### **Kubernetes Deployment (Planned)**

**Features:**
- Horizontal Pod Autoscaler (HPA) - Scale based on CPU/memory
- LoadBalancer service - Distribute traffic
- PersistentVolumeClaim - Model storage
- ConfigMap - Environment config
- Secrets - Credentials management

**Estimated Setup Time:** 2-3 hours

---

## ğŸ“š Documentation

### **Available Guides**

| Document | Description | Location |
|----------|-------------|----------|
| **PROJECT_START.md** | Complete startup guide | `docs/` |
| **PROJECT_STOP.md** | Shutdown procedures | `docs/` |
| **PRODUCTION_RISKS.md** | 13 identified risks + mitigations | `docs/` |
| **PROJECT_DOCUMENTATION.docx** | 7-page technical overview | `docs/` |
| **PRESENTATION_SCRIPT.docx** | 10-page presentation guide | `docs/` |
| **Architecture Diagrams** | 7 PDF flowcharts | `diagrams/` |

### **Architecture Diagrams**

1. **Master Diagram** - Complete system overview
2. **Data Pipeline** - S3 â†’ DVC â†’ Preprocessing
3. **Model Training** - ALS â†’ MLflow â†’ Registry
4. **Deployment** - Docker 4-service architecture
5. **User Request Flow** - End-to-end latency breakdown
6. **CI/CD Pipeline** - GitHub Actions workflow
7. **Monitoring** - Prometheus â†’ Grafana flow

---

## ğŸ¤ Contributing

We welcome contributions! Please follow these guidelines:

### **Setup Development Environment**

```bash
# Fork the repository
git clone https://github.com/YOUR_USERNAME/music-recommender-mlops.git
cd music-recommender-mlops

# Create virtual environment
python -m venv venv
source venv/bin/activate  # macOS/Linux
# OR: venv\Scripts\activate  # Windows

# Install dev dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Install pre-commit hooks
pre-commit install
```

### **Development Workflow**

1. Create feature branch: `git checkout -b feature/your-feature`
2. Make changes and add tests
3. Run tests: `pytest tests/ -v`
4. Format code: `black src/ && isort src/`
5. Commit: `git commit -m "Add feature X"`
6. Push: `git push origin feature/your-feature`
7. Create Pull Request

### **Code Standards**

- âœ… Python 3.12+ compatible
- âœ… Type hints for functions
- âœ… Docstrings (Google style)
- âœ… Tests for new features (pytest)
- âœ… <100 characters per line
- âœ… Black formatting
- âœ… Pass all CI/CD checks

---

## ğŸ‘¥ Team

**Siddhish Nirgude**
- Role: Data Pipeline, Model Development, MLflow Integration
- Email: nirgudes@msu.edu
- GitHub: [@SiddhishNirgude](https://github.com/SiddhishNirgude)

**Sharod Williams**
- Role: Deployment, Monitoring, CI/CD, Infrastructure
- Email: willi645@msu.edu

**Course:** STT890 - Machine Learning Operations  
**Institution:** Michigan State University  
**Semester:** Fall 2024

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Last.fm** for providing the 360K user dataset
- **Michigan State University** for computational resources
- **Anthropic** for Claude AI assistance in documentation
- **Open Source Community** for the amazing tools (FastAPI, Streamlit, MLflow, etc.)

---

## ğŸ“ Support

**Issues:** https://github.com/SiddhishNirgude/music-recommender-mlops/issues

**Discussions:** https://github.com/SiddhishNirgude/music-recommender-mlops/discussions

**Documentation:** See `docs/` folder for detailed guides

---

## ğŸ“ Academic Context

This project was developed as part of STT890 (Machine Learning Operations) coursework, demonstrating:
- Complete ML lifecycle implementation
- Production-ready deployment practices
- Automated testing and CI/CD
- Real-time monitoring and observability
- Risk management and mitigation strategies

**Grade Requirements Met:**
- âœ… Process documentation (6 detailed diagrams)
- âœ… Online data ingestion (DVC + AWS S3)
- âœ… Data and model repositories (versioned)
- âœ… Predictive modeling (ALS collaborative filtering)
- âœ… User-accessible deployment (Streamlit UI)
- âœ… Monitoring dashboards (Grafana 6 panels)
- âœ… Production risks document (13 risks identified)

---

## ğŸ“Š Project Statistics

```
Total Lines of Code: ~5,000
Python Files: 25
Docker Containers: 4
Tests: 52 (98% passing)
Documentation Pages: 50+
Architecture Diagrams: 7
Deployment Time: 30 seconds
Training Time: 13 minutes (production model)
Model Size: 370 MB
Dataset Size: 1.64 GB
Total Interactions: 17.5M
Response Time: 0.18s average
Uptime: 99%+
```

---

**â­ Star this repo if you found it helpful!**

**ğŸ”— Connect:** [GitHub](https://github.com/SiddhishNirgude) â€¢ [LinkedIn](https://linkedin.com/in/siddhishnirgude)

---

*Last Updated: December 2024*
